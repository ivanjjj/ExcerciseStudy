---
title: "Excercise Quality Study"
author: "Ivan Jennings"
date: "03/04/2021"
output:
  html_document:
    keep_md: yes

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary

In this project, my goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants using devices such as Jawbone Up, Nike FuelBand, and Fitbit to quantify how well the subjects are exercising. I will be using data from here http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

## Loading Data

First I will load necessary R libraries that I will need to complete my analysis.

```{r libraries, message=FALSE}
library(dplyr)
library(caret)
library(lubridate)
library(ggplot2)
library(randomForest)
library(e1071)
library(GGally)

```

Now I will download the data, load it into R and clean the data for analysis. I will import the testing set as "validation" as I will split the training data further for later validation.

```{r import data}
training_file_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testing_file_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(training_file_url, "training_test.csv", method = "curl")
download.file(testing_file_url, "validation.csv", method = "curl")
training_test <- read.csv(file.path(getwd(), "training_test.csv"), row.names = 1, stringsAsFactors = FALSE)
validation <- read.csv(file.path(getwd(), "validation.csv"), row.names = 1, stringsAsFactors = FALSE)
```

## Clean Data

Now that we have the data loaded in, let's explore the data using a few different R commands such as str(testing), str(training) - I haven't included the output here as there are 159 columns as we can see here from the dim command.

```{r explore data}
dim(training_test)
```

Let's go ahead and clean up some of these variables.

```{r clean data}

## get columns with no data in validation set
rows_with_data <- !as.vector(sapply(validation, function(x)all(is.na(x))))
## drop columns without data in validation set
training_test <- training_test[,rows_with_data]
validation <- validation[,rows_with_data]


## convert char col to factor

training_test$classe <- factor(training_test$classe)

## remove unnecessary data
training_test <- training_test %>%
  select(-c(1:6))
validation <- validation %>%
  select(-c(1:6))

```

Let's check for NAs now that we have cleaned up our data

```{r check NAs}
colSums(is.na(training_test))
colSums(is.na(validation))
```

We can see that there are 0 columns with NA values since we removed the columns that we do not have data for in the final validation set.

## Explore Data

Now that we have a clean set of data, let's split up our data as follows:

training_test (originally training data) will be split 70/30 into training and test data.
validation (originally test data) will be left seperate and we will use part of the original training set as test data instead so that we will only need to use the validation set once at the end.

```{r split set}
set.seed(444)
inTrain <- createDataPartition(training_test$classe, p=0.7, list=FALSE)
training <- training_test[inTrain,]
test <- training_test[-inTrain,]
```

```{r model}

ggcorr(training, geom = "text", nbreaks = 5, palette = "RdYlBu", hjust = 1)

correlated_variables <- findCorrelation(cor(training[,1:52]), cutoff = 0.6, exact = TRUE)

training <- training[,-(correlated_variables)]

fit_rpart <- train(classe~., method="rpart", data=training)

fit_gbm <- train(classe~., method="gbm", data=training)
fit_lda <- train(classe~., method="lda", data=training)
fit_rf <- train(classe~., method="rf", data=training)

```